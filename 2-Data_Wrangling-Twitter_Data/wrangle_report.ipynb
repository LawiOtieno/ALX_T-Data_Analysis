{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Wrangling Report</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* Introduction\n",
    "\n",
    "* Wrangling Processes\n",
    "    1. Gathering data\n",
    "    2. Assessing data\n",
    "    3. Cleaning data\n",
    "    4. Storing data\n",
    "\n",
    "* Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "The dataset (archive) used for __Wrangling Process__ was from a popular Twitter account, __WeRateDogs__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Softwares or libraries__ used include: pandas, numpy, tweepy, seaborn, matplotlib and BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Gathering data\n",
    "Three datasets were gathered using different methods.\n",
    "* __The WeRateDogs Twitter archive__, `twitter_archive_enhanced.csv`. This file was downloaded manually by clicking link which was provided.\n",
    "\n",
    "* __The tweet image predictions__, `image_predictions.tsv`. This file was downloaded programmatically using link that was provided and request library.\n",
    "\n",
    "* __Additional data from the Twitter API__. `tweet_json.txt`. Tweepy library and Twitter Developer Account Credentials were used access, download and save this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Assessing data\n",
    "This process involved __Visual__ and __Programmatic__ assessment. Then some of the identified issues were noted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quality issues\n",
    "\n",
    "1. Erroneous datatypes(tweet_id, timestamp) - `twitter_archive_enhanced`\n",
    "\n",
    "2. There are retweets and tweet replies but I only need original ratings - `twitter_archive_enhanced`\n",
    "\n",
    "3. Some missing names are 'None' instead of 'NaN' and othe are dummy such as _a_, an__, the__ - `twitter_archive_enhanced`\n",
    "\n",
    "4. Source column is in HTML format - `twitter_archive_enhanced`\n",
    "\n",
    "5. Source column have string datatype instead of category datatype - `twitter_archive_enhanced`\n",
    "\n",
    "6. Some tweeets have wrong denominator ratings,  - `twitter_archive_enhanced`\n",
    "\n",
    "7. Decimal ratings are not captured correctly  - `twitter_archive_enhanced`\n",
    "\n",
    "8. Wrong data types for tweet_id - `image_predictions`\n",
    "\n",
    "9. Some names in columns _p1_, _p2_, _p3_ are in uppercase while others in lowercase - columns (p1_conf,p2_conf_p3_conf) should be _confidence_ instead of _conf_ - `image_predictions`\n",
    "\n",
    "10. ID column name should be \"tweet_id\" instead of \"id\" - `tweets_data`\n",
    "\n",
    "11. Incorrect datatype for tweet_id - `tweets_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tidiness issues\n",
    "\n",
    "1. Dog classes (doggo, floofer, pupper, puppo) should be in one column - `twitter_archive_enhanced`\n",
    "\n",
    "2. All datasets (`twitter_archive_enhanced`, `image_predictions`, `tweets_data`) can be merged into one dataframe\n",
    "\n",
    "3. __Merge__ some columns then __remove__ unuseful columns (for my analysis) - __in merged dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Cleaning data\n",
    "First, I made copies of the 3 datasets that were gathered.\n",
    "\n",
    "Data Wrangling Process was divided into 3 parts __Define__, __Code__ and __Test__. All Issues listed in assessment outcome were cleaned.\n",
    "\n",
    "* Quality Issues\n",
    "\n",
    "* Tidiness Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Storing data\n",
    "After __cleaning__ the 3 copies of datasets, I merged them into one dataset and store the master dataset as __Twitter_archive_master.csv__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Eventhough it took me longer to get __Twitter Developer Account__ credentials, I managed to gather all the data that was required, then assessed, cleaned and stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Lawrence OTIENO</h3>\n",
    "<h5 align=\"center\">Phone: +254708581688</h5>\n",
    "<h5 align=\"center\">Email: lawifirst@gmail.com</h5>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
